#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Oct  5 21:52:10 2019

@author: ishank
"""
#%%
import csv
import numpy as np
import matplotlib.pyplot as plt
from random import randrange
from sklearn import svm
from sklearn.metrics import accuracy_score
from cvxopt import matrix as cvxopt_matrix
from cvxopt import solvers as cvxopt_solvers
#%%

data=[]
with open("data.csv") as csv_file:
    csv_reader = csv.reader(csv_file)
    for row in csv_reader:
        data.append(row)
    table=np.array(data)
print(table.shape)
#%%
label=(table[:,25])
label=label.astype(np.float)
print(label.shape)
design=table[:,0:25]
design=design.astype(np.float)
#%%
def form_design_for_binary(a,b,design,label):
    X_sub = np.array([design[j] for j in [i for i, x in enumerate(label) if x == a or x == b]])
    Y_sub = np.array([i for i in label if i == a or i == b])
    return X_sub,Y_sub
#%%
x_sub,y_sub=form_design_for_binary(0,1,design,label)
#%% split data into k folds
def cross_validation_split(X, y, folds):
    X_split = list()
    y_split = list()
    X_copy = list(X)
    y_copy = list(y)
    fold_size = int(len(X) / folds)
    for i in range(folds):
        X_fold = list()
        y_fold = list()
        while len(X_fold) < fold_size:
            index = randrange(len(X_copy))
            X_fold.append(X_copy.pop(index))
            y_fold.append(y_copy.pop(index))
        X_split.append(np.array(X_fold))
        y_split.append(np.reshape(np.array(y_fold), (fold_size,1)))
    return X_split, y_split
#%%
hyp = svm.SVC(gamma='scale')
hyp.fit(x_sub, y_sub) 
check=[]
y_sub-hyp.predict(x_sub)
#%% for 1st 10 features
#x_sub=x_sub[:,0:10]
#%%linear kernel
c_range=np.linspace(0.0001,0.01,num=50)
gamma_range=np.linspace(0,1,num=10)
p_range=np.linspace(0,5,num=10)
folds=6
error_total=[]
for c in c_range:
    x_cross,y_cross=cross_validation_split(x_sub, y_sub, folds)
    ac=0
    for f in range(0,folds):
        x_cross_train=np.empty(shape=(0,25))
        y_cross_train=np.empty(shape=(0,1))
        x_cross_test=x_cross[f]
        y_cross_test=y_cross[f]
        for i in range(0,folds):
            if(i!=f):
                x_cross_train=np.concatenate((x_cross_train, x_cross[i]),axis=0)
                y_cross_train=np.concatenate((y_cross_train, y_cross[i]),axis=0)
        hyp = svm.SVC(C=c, kernel='linear')
        hyp.fit(x_cross_train, y_cross_train.ravel())
        pred=hyp.predict(x_cross_test)
        #error=error+np.sum(np.absolute(y_cross_test-pred))
        ac=ac+accuracy_score(y_cross_test, pred)
    error_total.append(ac/folds)
#%%
plt.plot(c_range,error_total)
#%% kernel=rbf
c_range=np.linspace(0.05,0.0001,num=10)
gamma_range=np.linspace(0.001,0.1,num=10)
p_range=np.linspace(0,5,num=6)
folds=6
M=np.empty([len(c_range),len(gamma_range)])
a=-1
b=-1
for c in c_range:
    a=a+1
    b=-1
    for g in gamma_range:
        b=b+1
        x_cross,y_cross=cross_validation_split(x_sub, y_sub, folds)
        ac=0
        for f in range(0,folds):
            x_cross_train=np.empty(shape=(0,25))
            y_cross_train=np.empty(shape=(0,1))
            x_cross_test=x_cross[f]
            y_cross_test=y_cross[f]
            for i in range(0,folds):
                if(i!=f):
                    x_cross_train=np.concatenate((x_cross_train, x_cross[i]),axis=0)
                    y_cross_train=np.concatenate((y_cross_train, y_cross[i]),axis=0)
            hyp = svm.SVC(C=c, kernel='rbf',degree=3, gamma=g,decision_function_shape='ovo')
            hyp.fit(x_cross_train, y_cross_train.ravel())
            pred=hyp.predict(x_cross_test)
            #error=error+np.sum(np.absolute(y_cross_test-pred))
            ac=ac+accuracy_score(y_cross_test, pred)
        M[a][b]=ac/folds
print(np.amax(M))
print(np.where(np.amax(M)==M))
#%% kernel=poly
c_range=np.linspace(0.04,0.8,num=10)
gamma_range=np.linspace(0.001,0.1,num=10)
p_range=np.linspace(0,5,num=6)
folds=10
M=np.empty([len(c_range),len(gamma_range),len(p_range)])
a=-1
b=-1
d=-1
for c in c_range:
    a=a+1
    b=-1
    for g in gamma_range:
        b=b+1
        d=-1
        for p in p_range:
            d=d+1
            x_cross,y_cross=cross_validation_split(x_sub, y_sub, folds)
            ac=0
            for f in range(0,folds):
                x_cross_train=np.empty(shape=(0,25))
                y_cross_train=np.empty(shape=(0,1))
                x_cross_test=x_cross[f]
                y_cross_test=y_cross[f]
                for i in range(0,folds):
                    if(i!=f):
                        x_cross_train=np.concatenate((x_cross_train, x_cross[i]),axis=0)
                        y_cross_train=np.concatenate((y_cross_train, y_cross[i]),axis=0)
                hyp = svm.SVC(C=c, kernel='poly',degree=p, gamma=g,decision_function_shape='ovo')
                hyp.fit(x_cross_train, y_cross_train.ravel())
                pred=hyp.predict(x_cross_test)
                ac=ac+accuracy_score(y_cross_test, pred)
            M[a][b][d]=ac/folds
print(np.amax(M))
print(np.where(np.amax(M)==M))
#%% test train accuracy
x_train=x_sub[0:450]
x_test=x_sub[450:600]
y_train=y_sub[0:450]
y_test=y_sub[450:600]
hyp = svm.SVC(C=0.0167333, kernel='linear',degree=3, gamma=0.012)
hyp.fit(x_train, y_train.ravel())
train_pred=hyp.predict(x_train)
test_pred=hyp.predict(x_test)
train_ac=accuracy_score(y_train,train_pred)
test_ac=accuracy_score(y_test,test_pred)
print(train_ac)
print(test_ac)
#%% test train graph
x_train=x_sub[0:450]
x_test=x_sub[450:600]
y_train=y_sub[0:450]
y_test=y_sub[450:600]
train_acc=[]
test_acc=[]
c_range=np.linspace(0.15,0.001,num=50)
for c in c_range:
    hyp = svm.SVC(C=0.00583158, kernel='rbf',degree=3, gamma=c)
    hyp.fit(x_train, y_train.ravel())
    train_pred=hyp.predict(x_train)
    test_pred=hyp.predict(x_test)
    train_ac=accuracy_score(y_train,train_pred)
    test_ac=accuracy_score(y_test,test_pred)
    train_acc.append(1-train_ac)
    test_acc.append(1-test_ac)
plt.title('Error graph')
plt.xlabel('C values')
plt.ylabel('Accuracy')
e,=plt.plot(c_range,train_acc,label='train error')
f,=plt.plot(c_range,test_acc, label='test error')
plt.legend(handles=[e, f])
#%% Multi class classification
c_range=np.linspace(0.05,0.2,num=10)
gamma_range=np.linspace(0,1,num=10)
p_range=np.linspace(0,5,num=10)
folds=10
error_total=[]
for c in c_range:
    x_cross,y_cross=cross_validation_split(design, label, folds)
    ac=0
    for f in range(0,folds):
        x_cross_train=np.empty(shape=(0,25))
        y_cross_train=np.empty(shape=(0,1))
        x_cross_test=x_cross[f]
        y_cross_test=y_cross[f]
        for i in range(0,folds):
            if(i!=f):
                x_cross_train=np.concatenate((x_cross_train, x_cross[i]),axis=0)
                y_cross_train=np.concatenate((y_cross_train, y_cross[i]),axis=0)
        hyp = svm.SVC(C=c, kernel='linear',decision_function_shape='ovo')
        hyp.fit(x_cross_train, y_cross_train.ravel())
        pred=hyp.predict(x_cross_test)
        #error=error+np.sum(np.absolute(y_cross_test-pred))
        ac=ac+accuracy_score(y_cross_test, pred)
    error_total.append(ac/folds)
#%% test train accuracy
x_train=x_sub[0:2250]
x_test=x_sub[2250:3000]
y_train=y_sub[0:8000]
y_test=y_sub[8000:10000]
hyp = svm.SVC(C=8, kernel='rbf',degree=3, gamma='scale' ,decision_function_shape='ovo')
hyp.fit(x_train, y_train.ravel())
train_pred=hyp.predict(x_train)
test_pred=hyp.predict(x_test)
train_ac=accuracy_score(y_train,train_pred)
test_ac=accuracy_score(y_test,test_pred)
print(train_ac)
print(test_ac)
#%% test train graph
x_train=design[0:8000]
x_test=design[8000:10000]
y_train=label[0:8000]
y_test=label[8000:10000]
train_acc=[]
test_acc=[]
c_range=np.linspace(0.5,9,num=20)
for c in c_range:
    hyp = svm.SVC(C=c, kernel='rbf',degree=3, gamma='scale',decision_function_shape='ovo')
    hyp.fit(x_train, y_train.ravel())
    train_pred=hyp.predict(x_train)
    test_pred=hyp.predict(x_test)
    train_ac=accuracy_score(y_train,train_pred)
    test_ac=accuracy_score(y_test,test_pred)
    train_acc.append(1-train_ac)
    test_acc.append(1-test_ac)
plt.title('Error graph')
plt.xlabel('C values')
plt.ylabel('Error')
e,=plt.plot(c_range,train_acc,label='train error')
f,=plt.plot(c_range,test_acc, label='test error')
plt.legend(handles=[e, f])
#%%
def linear_kernel(x1, x2):
    return np.dot(x1, x2)

def polynomial_kernel(x, y, p=3):
    return (1 + np.dot(x, y)) ** p

def gaussian_kernel(x, y, sigma=5.0):
    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))
#%%
def perform_cvx_opt(X, y, C = None, soft_threshold = 1e-4, kernel = 'rbf', p = 3, gamma = 1e-1):
    n_samples, n_features = X.shape
    K = np.zeros((n_samples, n_samples))
    for i in range(n_samples):
        for j in range(n_samples):
            if kernel == 'linear':
                K[i,j] = linear_kernel(X[i], X[j])
            elif kernel == 'poly':
                K[i,j] = polynomial_kernel(X[i], X[j], p)
            elif kernel == 'rbf' :
                K[i, j] = gaussian_kernel(X[i], X[j], gamma)
                
    P = cvxopt_matrix(np.outer(y, y) * K)
    q = cvxopt_matrix(np.ones(n_samples) * -1)
    A = cvxopt_matrix(y.reshape(1, -1))
    A = cvxopt_matrix(A, (1, n_samples), 'd')
    b = cvxopt_matrix(0.0)
    
    if C is None:
        G = cvxopt_matrix(np.diag(np.ones(n_samples) * -1))
        h = cvxopt_matrix(np.zeros(n_samples))
    else:
        tmp1 = np.diag(np.ones(n_samples) * -1)
        tmp2 = np.identity(n_samples)
        G = cvxopt_matrix(np.vstack((tmp1, tmp2)))
        tmp1 = np.zeros(n_samples)
        tmp2 = np.ones(n_samples) * C
        h = cvxopt_matrix(np.hstack((tmp1, tmp2)))
    solution = cvxopt_solvers.qp(P, q, G, h, A, b)
    
    a = np.ravel(solution['x'])

    w = np.matrix(np.zeros((1, n_features)))
    for i in range(n_samples):
        w += a[i] * y[i] * X[i]
        
    intercept = 0
    for i in range(n_samples):
        if a[i] > soft_threshold:
            intercept = y[i] - w.dot(np.transpose(X[i]))
            break
    
    intercept = float(intercept)
    
    return w.T, intercept, a
#%%
x_train=x_sub[0:450]
x_test=x_sub[450:600]
for i in range(0,len(y_sub)):
    if(y_sub[i]==0):
        y_sub[i]=-1
y_train=y_sub[0:450]
y_test=y_sub[450:600]
j,l,k=perform_cvx_opt(x_train,y_train, C=0.000017286, kernel='rbf', gamma=0.0766316)
#%%
#def accuracy_score(a,b):
#    c=np.sum(np.absolute(np.absolute(a)-np.absolute(b)))
#    return 1-(c/len(a))
#%%
inter=np.empty([150,1])
inter.fill(l)
predic=np.matmul(x_test,j)+inter
for i in range(0, len(predic)):
    if(predic[i])>0:
        predic[i]=1
    else:
        predic[i]=-1
t_ac=accuracy_score(y_test,predic)
print(t_ac)
#%%
data2=[]
with open("kaggle_test.csv") as csv_file:
    csv_reader = csv.reader(csv_file)
    for row in csv_reader:
        data2.append(row)
    table2=np.array(data2)
print(table2.shape)
#%%
design2=table2[:,0:25]
design2=design2.astype(np.float)
#%%
pred=hyp.predict(design2)
pred=pred.astype(int)